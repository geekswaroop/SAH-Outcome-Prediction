{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAH-NN_Alive/Dead.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1M7NHj5a-ug",
        "colab_type": "code",
        "outputId": "fde7b376-c0d3-4d6b-e9d1-743173308edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GREOHC2bLWc",
        "colab_type": "code",
        "outputId": "bdc2a950-94ed-41d4-8e02-68c0785e6d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df = pd.read_csv('manipal_sah_tr.csv')\n",
        "df_test = pd.read_csv('manipal_sah_test.csv')\n",
        "df.drop(['Radiological Vasospas1', 'Clinical ischemic de0icits', 'Outcome at Discharge'], inplace = True,  axis = 1) \n",
        "df_test.drop(['Radiological Vasospas1', 'Clinical ischemic de0icits', 'Outcome at Discharge'], inplace = True,  axis = 1) \n",
        "\n",
        "print(df.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Age  Sex  Hypertension  Daibetes  WFNS grade  Outcome at 3 months\n",
            "0   56    1             0         1           1                    1\n",
            "1   54    1             0         1           1                    5\n",
            "2   66    1             0         1           2                    5\n",
            "3   46    1             0         0           1                    5\n",
            "4   67    0             1         1           2                    5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xL_48JLbL49",
        "colab_type": "code",
        "outputId": "52c3015b-c00d-425a-f6cb-a13a62861483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "X = df.loc[:, 'Age':'WFNS grade']\n",
        "Y = df.loc[:,'Outcome at 3 months']\n",
        "#Y = Y.to_frame()\n",
        "X.info()\n",
        "#Y.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 627 entries, 0 to 626\n",
            "Data columns (total 5 columns):\n",
            "Age             627 non-null int64\n",
            "Sex             627 non-null int64\n",
            "Hypertension    627 non-null int64\n",
            "Daibetes        627 non-null int64\n",
            "WFNS grade      627 non-null int64\n",
            "dtypes: int64(5)\n",
            "memory usage: 24.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGELhhX4bNSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(Y)):\n",
        "  if Y[i]>=2:\n",
        "    Y[i] = 0\n",
        "  else:\n",
        "    Y[i] = 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9lu_jy5bYxw",
        "colab_type": "code",
        "outputId": "0992f59c-5e4b-4978-a471-4e8f2696a5af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0      1\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "622    0\n",
            "623    0\n",
            "624    0\n",
            "625    0\n",
            "626    0\n",
            "Name: Outcome at 3 months, Length: 627, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS72mVv1baSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=42, stratify=Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tqg8kFIbdYc",
        "colab_type": "code",
        "outputId": "5b62bc0f-14e7-474f-c782-5f53cefa1d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "num_classes=2\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim = 5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               768       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 34,050\n",
            "Trainable params: 34,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I69FLtj0bf04",
        "colab_type": "code",
        "outputId": "77022c4f-7414-48c7-9dd7-0f1bc0cfd157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "class_weight = {0: 6.,\n",
        "                1: 6.,\n",
        "                2: 3.,\n",
        "                3: 3.,\n",
        "                4: 1.}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYWEuIL9bhYj",
        "colab_type": "code",
        "outputId": "dfe658db-ed75-4d56-ddea-d1fb7dc4687d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 2\n",
        "epochs = 100\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=2,\n",
        "                    validation_data=(X_test, y_test),class_weight=class_weight)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 501 samples, validate on 126 samples\n",
            "Epoch 1/100\n",
            " - 0s - loss: 1.6425 - acc: 0.9182 - val_loss: 0.2620 - val_acc: 0.9206\n",
            "Epoch 2/100\n",
            " - 0s - loss: 1.6411 - acc: 0.9182 - val_loss: 0.2619 - val_acc: 0.9206\n",
            "Epoch 3/100\n",
            " - 0s - loss: 1.6955 - acc: 0.9162 - val_loss: 0.2910 - val_acc: 0.9206\n",
            "Epoch 4/100\n",
            " - 0s - loss: 1.7000 - acc: 0.9182 - val_loss: 0.2739 - val_acc: 0.9206\n",
            "Epoch 5/100\n",
            " - 0s - loss: 1.7239 - acc: 0.9182 - val_loss: 0.2650 - val_acc: 0.9206\n",
            "Epoch 6/100\n",
            " - 0s - loss: 1.6696 - acc: 0.9182 - val_loss: 0.2677 - val_acc: 0.9206\n",
            "Epoch 7/100\n",
            " - 0s - loss: 1.6744 - acc: 0.9182 - val_loss: 0.2626 - val_acc: 0.9206\n",
            "Epoch 8/100\n",
            " - 0s - loss: 1.6380 - acc: 0.9182 - val_loss: 0.2623 - val_acc: 0.9206\n",
            "Epoch 9/100\n",
            " - 0s - loss: 1.6515 - acc: 0.9182 - val_loss: 0.2686 - val_acc: 0.9206\n",
            "Epoch 10/100\n",
            " - 0s - loss: 1.6544 - acc: 0.9182 - val_loss: 0.2623 - val_acc: 0.9206\n",
            "Epoch 11/100\n",
            " - 0s - loss: 1.6375 - acc: 0.9182 - val_loss: 0.2638 - val_acc: 0.9206\n",
            "Epoch 12/100\n",
            " - 0s - loss: 1.6427 - acc: 0.9182 - val_loss: 0.2640 - val_acc: 0.9206\n",
            "Epoch 13/100\n",
            " - 0s - loss: 1.7194 - acc: 0.9182 - val_loss: 0.2623 - val_acc: 0.9206\n",
            "Epoch 14/100\n",
            " - 0s - loss: 1.6496 - acc: 0.9182 - val_loss: 0.2690 - val_acc: 0.9206\n",
            "Epoch 15/100\n",
            " - 0s - loss: 1.6799 - acc: 0.9182 - val_loss: 0.2638 - val_acc: 0.9206\n",
            "Epoch 16/100\n",
            " - 0s - loss: 1.7010 - acc: 0.9182 - val_loss: 0.2651 - val_acc: 0.9206\n",
            "Epoch 17/100\n",
            " - 0s - loss: 1.7147 - acc: 0.9182 - val_loss: 0.2673 - val_acc: 0.9206\n",
            "Epoch 18/100\n",
            " - 0s - loss: 1.7042 - acc: 0.9182 - val_loss: 0.2643 - val_acc: 0.9206\n",
            "Epoch 19/100\n",
            " - 0s - loss: 1.6530 - acc: 0.9182 - val_loss: 0.2620 - val_acc: 0.9206\n",
            "Epoch 20/100\n",
            " - 0s - loss: 1.6435 - acc: 0.9182 - val_loss: 0.2628 - val_acc: 0.9206\n",
            "Epoch 21/100\n",
            " - 0s - loss: 1.6516 - acc: 0.9182 - val_loss: 0.2644 - val_acc: 0.9206\n",
            "Epoch 22/100\n",
            " - 0s - loss: 1.6674 - acc: 0.9182 - val_loss: 0.2612 - val_acc: 0.9206\n",
            "Epoch 23/100\n",
            " - 0s - loss: 1.6356 - acc: 0.9182 - val_loss: 0.2624 - val_acc: 0.9206\n",
            "Epoch 24/100\n",
            " - 0s - loss: 1.6353 - acc: 0.9182 - val_loss: 0.2620 - val_acc: 0.9206\n",
            "Epoch 25/100\n",
            " - 0s - loss: 1.6420 - acc: 0.9182 - val_loss: 0.2621 - val_acc: 0.9206\n",
            "Epoch 26/100\n",
            " - 0s - loss: 1.6500 - acc: 0.9182 - val_loss: 0.2622 - val_acc: 0.9206\n",
            "Epoch 27/100\n",
            " - 0s - loss: 1.6357 - acc: 0.9182 - val_loss: 0.2618 - val_acc: 0.9206\n",
            "Epoch 28/100\n",
            " - 0s - loss: 1.6382 - acc: 0.9182 - val_loss: 0.2616 - val_acc: 0.9206\n",
            "Epoch 29/100\n",
            " - 0s - loss: 1.6294 - acc: 0.9182 - val_loss: 0.2637 - val_acc: 0.9206\n",
            "Epoch 30/100\n",
            " - 0s - loss: 1.6451 - acc: 0.9182 - val_loss: 0.2631 - val_acc: 0.9206\n",
            "Epoch 31/100\n",
            " - 0s - loss: 1.6523 - acc: 0.9182 - val_loss: 0.2616 - val_acc: 0.9206\n",
            "Epoch 32/100\n",
            " - 0s - loss: 1.6402 - acc: 0.9182 - val_loss: 0.2619 - val_acc: 0.9206\n",
            "Epoch 33/100\n",
            " - 0s - loss: 1.6442 - acc: 0.9182 - val_loss: 0.2653 - val_acc: 0.9206\n",
            "Epoch 34/100\n",
            " - 0s - loss: 1.6338 - acc: 0.9182 - val_loss: 0.2634 - val_acc: 0.9206\n",
            "Epoch 35/100\n",
            " - 0s - loss: 1.6472 - acc: 0.9182 - val_loss: 0.2627 - val_acc: 0.9206\n",
            "Epoch 36/100\n",
            " - 0s - loss: 1.6388 - acc: 0.9182 - val_loss: 0.2633 - val_acc: 0.9206\n",
            "Epoch 37/100\n",
            " - 0s - loss: 1.6560 - acc: 0.9182 - val_loss: 0.2636 - val_acc: 0.9206\n",
            "Epoch 38/100\n",
            " - 0s - loss: 1.6269 - acc: 0.9182 - val_loss: 0.2620 - val_acc: 0.9206\n",
            "Epoch 39/100\n",
            " - 0s - loss: 1.6410 - acc: 0.9182 - val_loss: 0.2629 - val_acc: 0.9206\n",
            "Epoch 40/100\n",
            " - 0s - loss: 1.6313 - acc: 0.9182 - val_loss: 0.2628 - val_acc: 0.9206\n",
            "Epoch 41/100\n",
            " - 0s - loss: 1.6537 - acc: 0.9182 - val_loss: 0.2641 - val_acc: 0.9206\n",
            "Epoch 42/100\n",
            " - 0s - loss: 1.6299 - acc: 0.9182 - val_loss: 0.2628 - val_acc: 0.9206\n",
            "Epoch 43/100\n",
            " - 0s - loss: 1.6313 - acc: 0.9182 - val_loss: 0.2658 - val_acc: 0.9206\n",
            "Epoch 44/100\n",
            " - 0s - loss: 1.6499 - acc: 0.9182 - val_loss: 0.2663 - val_acc: 0.9206\n",
            "Epoch 45/100\n",
            " - 0s - loss: 1.6703 - acc: 0.9182 - val_loss: 0.2622 - val_acc: 0.9206\n",
            "Epoch 46/100\n",
            " - 0s - loss: 1.6236 - acc: 0.9182 - val_loss: 0.2624 - val_acc: 0.9206\n",
            "Epoch 47/100\n",
            " - 0s - loss: 1.6254 - acc: 0.9182 - val_loss: 0.2628 - val_acc: 0.9206\n",
            "Epoch 48/100\n",
            " - 0s - loss: 1.6288 - acc: 0.9182 - val_loss: 0.2639 - val_acc: 0.9206\n",
            "Epoch 49/100\n",
            " - 0s - loss: 1.6309 - acc: 0.9182 - val_loss: 0.2647 - val_acc: 0.9206\n",
            "Epoch 50/100\n",
            " - 0s - loss: 1.6444 - acc: 0.9182 - val_loss: 0.2660 - val_acc: 0.9206\n",
            "Epoch 51/100\n",
            " - 0s - loss: 1.6518 - acc: 0.9182 - val_loss: 0.2634 - val_acc: 0.9206\n",
            "Epoch 52/100\n",
            " - 0s - loss: 1.6754 - acc: 0.9182 - val_loss: 0.2647 - val_acc: 0.9206\n",
            "Epoch 53/100\n",
            " - 0s - loss: 1.6449 - acc: 0.9182 - val_loss: 0.2629 - val_acc: 0.9206\n",
            "Epoch 54/100\n",
            " - 0s - loss: 1.6296 - acc: 0.9182 - val_loss: 0.2633 - val_acc: 0.9206\n",
            "Epoch 55/100\n",
            " - 0s - loss: 1.6224 - acc: 0.9182 - val_loss: 0.2646 - val_acc: 0.9206\n",
            "Epoch 56/100\n",
            " - 0s - loss: 1.6339 - acc: 0.9182 - val_loss: 0.2637 - val_acc: 0.9206\n",
            "Epoch 57/100\n",
            " - 0s - loss: 1.6306 - acc: 0.9182 - val_loss: 0.2643 - val_acc: 0.9206\n",
            "Epoch 58/100\n",
            " - 0s - loss: 1.6266 - acc: 0.9182 - val_loss: 0.2646 - val_acc: 0.9206\n",
            "Epoch 59/100\n",
            " - 0s - loss: 1.6332 - acc: 0.9182 - val_loss: 0.2642 - val_acc: 0.9206\n",
            "Epoch 60/100\n",
            " - 0s - loss: 1.6316 - acc: 0.9182 - val_loss: 0.2640 - val_acc: 0.9206\n",
            "Epoch 61/100\n",
            " - 0s - loss: 1.6176 - acc: 0.9182 - val_loss: 0.2653 - val_acc: 0.9206\n",
            "Epoch 62/100\n",
            " - 0s - loss: 1.6266 - acc: 0.9182 - val_loss: 0.2637 - val_acc: 0.9206\n",
            "Epoch 63/100\n",
            " - 0s - loss: 1.6221 - acc: 0.9182 - val_loss: 0.2632 - val_acc: 0.9206\n",
            "Epoch 64/100\n",
            " - 0s - loss: 1.6680 - acc: 0.9182 - val_loss: 0.2710 - val_acc: 0.9206\n",
            "Epoch 65/100\n",
            " - 0s - loss: 1.6450 - acc: 0.9182 - val_loss: 0.2630 - val_acc: 0.9206\n",
            "Epoch 66/100\n",
            " - 0s - loss: 1.6360 - acc: 0.9182 - val_loss: 0.2721 - val_acc: 0.9206\n",
            "Epoch 67/100\n",
            " - 0s - loss: 1.6439 - acc: 0.9182 - val_loss: 0.2643 - val_acc: 0.9206\n",
            "Epoch 68/100\n",
            " - 0s - loss: 1.6222 - acc: 0.9182 - val_loss: 0.2651 - val_acc: 0.9206\n",
            "Epoch 69/100\n",
            " - 0s - loss: 1.6209 - acc: 0.9182 - val_loss: 0.2645 - val_acc: 0.9206\n",
            "Epoch 70/100\n",
            " - 0s - loss: 1.6233 - acc: 0.9182 - val_loss: 0.2642 - val_acc: 0.9206\n",
            "Epoch 71/100\n",
            " - 0s - loss: 1.6152 - acc: 0.9182 - val_loss: 0.2654 - val_acc: 0.9206\n",
            "Epoch 72/100\n",
            " - 0s - loss: 1.6571 - acc: 0.9182 - val_loss: 0.2647 - val_acc: 0.9206\n",
            "Epoch 73/100\n",
            " - 0s - loss: 1.6236 - acc: 0.9182 - val_loss: 0.2665 - val_acc: 0.9206\n",
            "Epoch 74/100\n",
            " - 0s - loss: 1.6313 - acc: 0.9182 - val_loss: 0.2648 - val_acc: 0.9206\n",
            "Epoch 75/100\n",
            " - 0s - loss: 1.6422 - acc: 0.9182 - val_loss: 0.2714 - val_acc: 0.9206\n",
            "Epoch 76/100\n",
            " - 0s - loss: 1.6298 - acc: 0.9182 - val_loss: 0.2724 - val_acc: 0.9206\n",
            "Epoch 77/100\n",
            " - 0s - loss: 1.6524 - acc: 0.9182 - val_loss: 0.2644 - val_acc: 0.9206\n",
            "Epoch 78/100\n",
            " - 0s - loss: 1.6132 - acc: 0.9182 - val_loss: 0.2648 - val_acc: 0.9206\n",
            "Epoch 79/100\n",
            " - 0s - loss: 1.6207 - acc: 0.9182 - val_loss: 0.2622 - val_acc: 0.9206\n",
            "Epoch 80/100\n",
            " - 0s - loss: 1.6210 - acc: 0.9182 - val_loss: 0.2629 - val_acc: 0.9206\n",
            "Epoch 81/100\n",
            " - 0s - loss: 1.6725 - acc: 0.9182 - val_loss: 0.2651 - val_acc: 0.9206\n",
            "Epoch 82/100\n",
            " - 0s - loss: 1.6153 - acc: 0.9182 - val_loss: 0.2644 - val_acc: 0.9206\n",
            "Epoch 83/100\n",
            " - 0s - loss: 1.6197 - acc: 0.9182 - val_loss: 0.2647 - val_acc: 0.9206\n",
            "Epoch 84/100\n",
            " - 0s - loss: 1.6381 - acc: 0.9182 - val_loss: 0.2672 - val_acc: 0.9206\n",
            "Epoch 85/100\n",
            " - 0s - loss: 1.6319 - acc: 0.9182 - val_loss: 0.2648 - val_acc: 0.9206\n",
            "Epoch 86/100\n",
            " - 0s - loss: 1.6498 - acc: 0.9182 - val_loss: 0.2629 - val_acc: 0.9206\n",
            "Epoch 87/100\n",
            " - 0s - loss: 1.6236 - acc: 0.9182 - val_loss: 0.2652 - val_acc: 0.9206\n",
            "Epoch 88/100\n",
            " - 0s - loss: 1.6404 - acc: 0.9182 - val_loss: 0.2637 - val_acc: 0.9206\n",
            "Epoch 89/100\n",
            " - 0s - loss: 1.6261 - acc: 0.9182 - val_loss: 0.2634 - val_acc: 0.9206\n",
            "Epoch 90/100\n",
            " - 0s - loss: 1.6234 - acc: 0.9182 - val_loss: 0.2649 - val_acc: 0.9206\n",
            "Epoch 91/100\n",
            " - 0s - loss: 1.6316 - acc: 0.9182 - val_loss: 0.2642 - val_acc: 0.9206\n",
            "Epoch 92/100\n",
            " - 0s - loss: 1.6162 - acc: 0.9182 - val_loss: 0.2647 - val_acc: 0.9206\n",
            "Epoch 93/100\n",
            " - 0s - loss: 1.6134 - acc: 0.9182 - val_loss: 0.2665 - val_acc: 0.9206\n",
            "Epoch 94/100\n",
            " - 0s - loss: 1.6279 - acc: 0.9182 - val_loss: 0.2645 - val_acc: 0.9206\n",
            "Epoch 95/100\n",
            " - 0s - loss: 1.6326 - acc: 0.9182 - val_loss: 0.2686 - val_acc: 0.9206\n",
            "Epoch 96/100\n",
            " - 0s - loss: 1.6583 - acc: 0.9182 - val_loss: 0.2691 - val_acc: 0.9206\n",
            "Epoch 97/100\n",
            " - 0s - loss: 1.6395 - acc: 0.9182 - val_loss: 0.2641 - val_acc: 0.9206\n",
            "Epoch 98/100\n",
            " - 0s - loss: 1.6191 - acc: 0.9182 - val_loss: 0.2650 - val_acc: 0.9206\n",
            "Epoch 99/100\n",
            " - 0s - loss: 1.6398 - acc: 0.9182 - val_loss: 0.2675 - val_acc: 0.9206\n",
            "Epoch 100/100\n",
            " - 0s - loss: 1.6162 - acc: 0.9182 - val_loss: 0.2644 - val_acc: 0.9206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcNWRmZwbiwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0_L_dODbqgJ",
        "colab_type": "code",
        "outputId": "0347b18c-50ec-49b2-ad4c-408e31308a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "np.argmax(model.predict_proba(df_test),axis = 1)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiU3Ha_kbrlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}