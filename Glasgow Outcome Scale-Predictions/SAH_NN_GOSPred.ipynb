{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAH-NN-GOSPred.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3gqbfZ-O-3u",
        "colab_type": "code",
        "outputId": "e760f703-fce8-49e8-d338-c680db55476f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiHrZI8rPPWp",
        "colab_type": "code",
        "outputId": "07e8bc71-ee4c-417e-f7a4-05484451e471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df = pd.read_csv('manipal_sah_tr.csv')\n",
        "df_test = pd.read_csv('manipal_sah_test.csv')\n",
        "df.drop(['Radiological Vasospas1', 'Clinical ischemic de0icits', 'Outcome at Discharge'], inplace = True,  axis = 1) \n",
        "df_test.drop(['Radiological Vasospas1', 'Clinical ischemic de0icits', 'Outcome at Discharge'], inplace = True,  axis = 1) \n",
        "\n",
        "print(df.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Age  Sex  Hypertension  Daibetes  WFNS grade  Outcome at 3 months\n",
            "0   56    1             0         1           1                    1\n",
            "1   54    1             0         1           1                    5\n",
            "2   66    1             0         1           2                    5\n",
            "3   46    1             0         0           1                    5\n",
            "4   67    0             1         1           2                    5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2OaVlsmP5Du",
        "colab_type": "code",
        "outputId": "8d8b0feb-bb31-4e4e-d856-143f0d01bae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "X = df.loc[:, 'Age':'WFNS grade']\n",
        "Y = df.loc[:,'Outcome at 3 months']\n",
        "Y_GOS = Y-1\n",
        "X.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 627 entries, 0 to 626\n",
            "Data columns (total 5 columns):\n",
            "Age             627 non-null int64\n",
            "Sex             627 non-null int64\n",
            "Hypertension    627 non-null int64\n",
            "Daibetes        627 non-null int64\n",
            "WFNS grade      627 non-null int64\n",
            "dtypes: int64(5)\n",
            "memory usage: 24.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiPOKD9zPjXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# # encode class values as integers\n",
        "# encoder = LabelEncoder()\n",
        "# encoder.fit(Y)\n",
        "# encoded_Y = encoder.transform(Y)\n",
        "# # convert integers to dummy variables (i.e. one hot encoded)\n",
        "# dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "\n",
        "# print(dummy_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG77xpkOQLes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def baseline_model():\n",
        "# \t# create model\n",
        "# \tmodel = Sequential()\n",
        "# \tmodel.add(Dense(8, input_dim=5, activation='relu'))\n",
        "# \tmodel.add(Dense(5, activation='softmax'))\n",
        "# \t# Compile model\n",
        "# \tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#   #model.summary()\n",
        "# \treturn model\n",
        " \n",
        "# estimator = KerasClassifier(build_fn=baseline_model, epochs=10, batch_size=5, verbose=0)\n",
        "# kfold = KFold(n_splits=10, shuffle=True)\n",
        "# results = cross_val_score(estimator, X, Y, cv=kfold)\n",
        "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_7mPSFLUOXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y_GOS,test_size=0.2, random_state=42, stratify=Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B73Re2GpTwqC",
        "colab_type": "code",
        "outputId": "5c35c82e-8507-4f0c-eb11-9c92b90958aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "num_classes=5\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim = 5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 128)               768       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 17,925\n",
            "Trainable params: 17,925\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhvba6GvVLNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "class_weight = {0: 6.,\n",
        "                1: 6.,\n",
        "                2: 3.,\n",
        "                3: 3.,\n",
        "                4: 1.}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii-IR60HVOij",
        "colab_type": "code",
        "outputId": "57405399-fc72-4a7b-fb24-f8aaa2b292dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 5\n",
        "epochs = 100\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=2,\n",
        "                    validation_data=(X_test, y_test),class_weight=class_weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 501 samples, validate on 126 samples\n",
            "Epoch 1/100\n",
            " - 0s - loss: 4.0990 - acc: 0.1816 - val_loss: 1.7086 - val_acc: 0.0794\n",
            "Epoch 2/100\n",
            " - 0s - loss: 4.1505 - acc: 0.2176 - val_loss: 1.5943 - val_acc: 0.1984\n",
            "Epoch 3/100\n",
            " - 0s - loss: 4.2333 - acc: 0.2176 - val_loss: 1.5782 - val_acc: 0.1746\n",
            "Epoch 4/100\n",
            " - 0s - loss: 4.2360 - acc: 0.2176 - val_loss: 1.5818 - val_acc: 0.1825\n",
            "Epoch 5/100\n",
            " - 0s - loss: 4.2056 - acc: 0.2096 - val_loss: 1.7514 - val_acc: 0.1429\n",
            "Epoch 6/100\n",
            " - 0s - loss: 4.1645 - acc: 0.2156 - val_loss: 1.5679 - val_acc: 0.2302\n",
            "Epoch 7/100\n",
            " - 0s - loss: 4.1603 - acc: 0.1796 - val_loss: 1.8310 - val_acc: 0.0794\n",
            "Epoch 8/100\n",
            " - 0s - loss: 4.1012 - acc: 0.2156 - val_loss: 1.6819 - val_acc: 0.0873\n",
            "Epoch 9/100\n",
            " - 0s - loss: 4.1098 - acc: 0.2116 - val_loss: 1.4634 - val_acc: 0.3492\n",
            "Epoch 10/100\n",
            " - 0s - loss: 4.0098 - acc: 0.2335 - val_loss: 1.4846 - val_acc: 0.3492\n",
            "Epoch 11/100\n",
            " - 0s - loss: 4.1116 - acc: 0.2834 - val_loss: 1.6479 - val_acc: 0.2143\n",
            "Epoch 12/100\n",
            " - 0s - loss: 4.0949 - acc: 0.1776 - val_loss: 1.3815 - val_acc: 0.4921\n",
            "Epoch 13/100\n",
            " - 0s - loss: 4.1705 - acc: 0.2934 - val_loss: 1.7364 - val_acc: 0.1825\n",
            "Epoch 14/100\n",
            " - 0s - loss: 3.9487 - acc: 0.2894 - val_loss: 1.5452 - val_acc: 0.1905\n",
            "Epoch 15/100\n",
            " - 0s - loss: 4.2794 - acc: 0.2056 - val_loss: 1.7521 - val_acc: 0.1984\n",
            "Epoch 16/100\n",
            " - 0s - loss: 4.0282 - acc: 0.2535 - val_loss: 1.4382 - val_acc: 0.4603\n",
            "Epoch 17/100\n",
            " - 0s - loss: 4.0310 - acc: 0.2335 - val_loss: 1.8656 - val_acc: 0.1111\n",
            "Epoch 18/100\n",
            " - 0s - loss: 4.0369 - acc: 0.2715 - val_loss: 1.7922 - val_acc: 0.0873\n",
            "Epoch 19/100\n",
            " - 0s - loss: 4.1111 - acc: 0.2375 - val_loss: 1.8819 - val_acc: 0.0794\n",
            "Epoch 20/100\n",
            " - 0s - loss: 4.1641 - acc: 0.2595 - val_loss: 1.4509 - val_acc: 0.4524\n",
            "Epoch 21/100\n",
            " - 0s - loss: 4.1204 - acc: 0.2555 - val_loss: 1.6066 - val_acc: 0.1587\n",
            "Epoch 22/100\n",
            " - 0s - loss: 4.2730 - acc: 0.2415 - val_loss: 1.8641 - val_acc: 0.0794\n",
            "Epoch 23/100\n",
            " - 0s - loss: 4.3468 - acc: 0.2355 - val_loss: 1.9620 - val_acc: 0.0794\n",
            "Epoch 24/100\n",
            " - 0s - loss: 4.1188 - acc: 0.2096 - val_loss: 1.5739 - val_acc: 0.1746\n",
            "Epoch 25/100\n",
            " - 0s - loss: 4.4281 - acc: 0.2116 - val_loss: 1.3711 - val_acc: 0.5079\n",
            "Epoch 26/100\n",
            " - 0s - loss: 4.2651 - acc: 0.2275 - val_loss: 1.5997 - val_acc: 0.1746\n",
            "Epoch 27/100\n",
            " - 0s - loss: 4.0400 - acc: 0.1916 - val_loss: 1.8213 - val_acc: 0.1190\n",
            "Epoch 28/100\n",
            " - 0s - loss: 4.1523 - acc: 0.2255 - val_loss: 1.4514 - val_acc: 0.4762\n",
            "Epoch 29/100\n",
            " - 0s - loss: 4.0706 - acc: 0.3134 - val_loss: 1.8034 - val_acc: 0.0635\n",
            "Epoch 30/100\n",
            " - 0s - loss: 4.2718 - acc: 0.2555 - val_loss: 1.5043 - val_acc: 0.3968\n",
            "Epoch 31/100\n",
            " - 0s - loss: 4.0756 - acc: 0.2615 - val_loss: 1.7681 - val_acc: 0.0635\n",
            "Epoch 32/100\n",
            " - 0s - loss: 4.0210 - acc: 0.2675 - val_loss: 1.4442 - val_acc: 0.4206\n",
            "Epoch 33/100\n",
            " - 0s - loss: 4.0707 - acc: 0.2894 - val_loss: 1.5416 - val_acc: 0.1825\n",
            "Epoch 34/100\n",
            " - 0s - loss: 4.1529 - acc: 0.2136 - val_loss: 1.7797 - val_acc: 0.1905\n",
            "Epoch 35/100\n",
            " - 0s - loss: 4.0135 - acc: 0.2495 - val_loss: 1.5805 - val_acc: 0.1825\n",
            "Epoch 36/100\n",
            " - 0s - loss: 4.0187 - acc: 0.1996 - val_loss: 1.5712 - val_acc: 0.1825\n",
            "Epoch 37/100\n",
            " - 0s - loss: 4.2096 - acc: 0.2575 - val_loss: 1.5607 - val_acc: 0.1984\n",
            "Epoch 38/100\n",
            " - 0s - loss: 4.0684 - acc: 0.2335 - val_loss: 1.5284 - val_acc: 0.1984\n",
            "Epoch 39/100\n",
            " - 0s - loss: 4.1609 - acc: 0.1816 - val_loss: 1.9625 - val_acc: 0.1746\n",
            "Epoch 40/100\n",
            " - 0s - loss: 4.1741 - acc: 0.1936 - val_loss: 1.6773 - val_acc: 0.1667\n",
            "Epoch 41/100\n",
            " - 0s - loss: 4.2203 - acc: 0.2615 - val_loss: 1.8779 - val_acc: 0.1825\n",
            "Epoch 42/100\n",
            " - 0s - loss: 4.0804 - acc: 0.2176 - val_loss: 1.6309 - val_acc: 0.1667\n",
            "Epoch 43/100\n",
            " - 0s - loss: 4.0085 - acc: 0.2116 - val_loss: 1.6396 - val_acc: 0.1349\n",
            "Epoch 44/100\n",
            " - 0s - loss: 4.0077 - acc: 0.2874 - val_loss: 1.8029 - val_acc: 0.0794\n",
            "Epoch 45/100\n",
            " - 0s - loss: 4.0973 - acc: 0.2894 - val_loss: 1.4590 - val_acc: 0.4683\n",
            "Epoch 46/100\n",
            " - 0s - loss: 4.0795 - acc: 0.2255 - val_loss: 1.4685 - val_acc: 0.4762\n",
            "Epoch 47/100\n",
            " - 0s - loss: 3.9683 - acc: 0.2735 - val_loss: 1.5503 - val_acc: 0.3651\n",
            "Epoch 48/100\n",
            " - 0s - loss: 4.0924 - acc: 0.2315 - val_loss: 1.6389 - val_acc: 0.1746\n",
            "Epoch 49/100\n",
            " - 0s - loss: 3.9641 - acc: 0.2655 - val_loss: 1.6926 - val_acc: 0.1032\n",
            "Epoch 50/100\n",
            " - 0s - loss: 4.0199 - acc: 0.2954 - val_loss: 1.6981 - val_acc: 0.1587\n",
            "Epoch 51/100\n",
            " - 0s - loss: 4.0150 - acc: 0.2375 - val_loss: 1.4198 - val_acc: 0.3968\n",
            "Epoch 52/100\n",
            " - 0s - loss: 4.0959 - acc: 0.2016 - val_loss: 1.5686 - val_acc: 0.1984\n",
            "Epoch 53/100\n",
            " - 0s - loss: 3.9364 - acc: 0.2974 - val_loss: 1.5828 - val_acc: 0.2063\n",
            "Epoch 54/100\n",
            " - 0s - loss: 4.0943 - acc: 0.1996 - val_loss: 1.3620 - val_acc: 0.4921\n",
            "Epoch 55/100\n",
            " - 0s - loss: 4.1017 - acc: 0.2335 - val_loss: 1.6761 - val_acc: 0.0635\n",
            "Epoch 56/100\n",
            " - 0s - loss: 4.2110 - acc: 0.2236 - val_loss: 1.7670 - val_acc: 0.1746\n",
            "Epoch 57/100\n",
            " - 0s - loss: 4.1851 - acc: 0.2575 - val_loss: 1.9677 - val_acc: 0.1190\n",
            "Epoch 58/100\n",
            " - 0s - loss: 4.0033 - acc: 0.2874 - val_loss: 1.6541 - val_acc: 0.1825\n",
            "Epoch 59/100\n",
            " - 0s - loss: 4.0586 - acc: 0.2176 - val_loss: 1.4948 - val_acc: 0.3730\n",
            "Epoch 60/100\n",
            " - 0s - loss: 4.0137 - acc: 0.2515 - val_loss: 1.5382 - val_acc: 0.1984\n",
            "Epoch 61/100\n",
            " - 0s - loss: 4.0176 - acc: 0.2495 - val_loss: 1.6046 - val_acc: 0.1587\n",
            "Epoch 62/100\n",
            " - 0s - loss: 3.9289 - acc: 0.2395 - val_loss: 1.8987 - val_acc: 0.0952\n",
            "Epoch 63/100\n",
            " - 0s - loss: 4.2526 - acc: 0.2675 - val_loss: 2.0365 - val_acc: 0.1746\n",
            "Epoch 64/100\n",
            " - 0s - loss: 3.9865 - acc: 0.2854 - val_loss: 1.7552 - val_acc: 0.1825\n",
            "Epoch 65/100\n",
            " - 0s - loss: 3.9247 - acc: 0.2196 - val_loss: 1.5019 - val_acc: 0.3968\n",
            "Epoch 66/100\n",
            " - 0s - loss: 4.0055 - acc: 0.2275 - val_loss: 1.4941 - val_acc: 0.3571\n",
            "Epoch 67/100\n",
            " - 0s - loss: 3.9472 - acc: 0.2615 - val_loss: 1.7287 - val_acc: 0.1270\n",
            "Epoch 68/100\n",
            " - 0s - loss: 4.0813 - acc: 0.2635 - val_loss: 1.5352 - val_acc: 0.3175\n",
            "Epoch 69/100\n",
            " - 0s - loss: 4.0867 - acc: 0.1996 - val_loss: 1.4983 - val_acc: 0.2540\n",
            "Epoch 70/100\n",
            " - 0s - loss: 4.0066 - acc: 0.2255 - val_loss: 1.5840 - val_acc: 0.1746\n",
            "Epoch 71/100\n",
            " - 0s - loss: 3.9659 - acc: 0.2196 - val_loss: 1.5570 - val_acc: 0.3413\n",
            "Epoch 72/100\n",
            " - 0s - loss: 3.9763 - acc: 0.2794 - val_loss: 1.5558 - val_acc: 0.2540\n",
            "Epoch 73/100\n",
            " - 0s - loss: 3.9261 - acc: 0.2275 - val_loss: 1.5454 - val_acc: 0.3651\n",
            "Epoch 74/100\n",
            " - 0s - loss: 3.8967 - acc: 0.2774 - val_loss: 1.6060 - val_acc: 0.3016\n",
            "Epoch 75/100\n",
            " - 0s - loss: 4.0024 - acc: 0.2415 - val_loss: 1.5072 - val_acc: 0.3968\n",
            "Epoch 76/100\n",
            " - 0s - loss: 3.9765 - acc: 0.2375 - val_loss: 1.5027 - val_acc: 0.2778\n",
            "Epoch 77/100\n",
            " - 0s - loss: 4.0165 - acc: 0.1597 - val_loss: 1.4797 - val_acc: 0.3016\n",
            "Epoch 78/100\n",
            " - 0s - loss: 4.0527 - acc: 0.3313 - val_loss: 1.7956 - val_acc: 0.1746\n",
            "Epoch 79/100\n",
            " - 0s - loss: 3.9976 - acc: 0.3293 - val_loss: 1.7141 - val_acc: 0.1270\n",
            "Epoch 80/100\n",
            " - 0s - loss: 3.8919 - acc: 0.2675 - val_loss: 1.7226 - val_acc: 0.0952\n",
            "Epoch 81/100\n",
            " - 0s - loss: 3.9273 - acc: 0.2096 - val_loss: 1.4407 - val_acc: 0.4603\n",
            "Epoch 82/100\n",
            " - 0s - loss: 3.9840 - acc: 0.2615 - val_loss: 1.4200 - val_acc: 0.3810\n",
            "Epoch 83/100\n",
            " - 0s - loss: 3.9388 - acc: 0.2236 - val_loss: 1.4674 - val_acc: 0.4444\n",
            "Epoch 84/100\n",
            " - 0s - loss: 3.9604 - acc: 0.2655 - val_loss: 1.5963 - val_acc: 0.1905\n",
            "Epoch 85/100\n",
            " - 0s - loss: 4.0664 - acc: 0.2814 - val_loss: 1.8089 - val_acc: 0.1111\n",
            "Epoch 86/100\n",
            " - 0s - loss: 3.9599 - acc: 0.2774 - val_loss: 1.6491 - val_acc: 0.1746\n",
            "Epoch 87/100\n",
            " - 0s - loss: 4.0351 - acc: 0.2774 - val_loss: 1.5922 - val_acc: 0.1825\n",
            "Epoch 88/100\n",
            " - 0s - loss: 4.0103 - acc: 0.2116 - val_loss: 1.4298 - val_acc: 0.4603\n",
            "Epoch 89/100\n",
            " - 0s - loss: 3.8967 - acc: 0.2315 - val_loss: 1.4723 - val_acc: 0.4603\n",
            "Epoch 90/100\n",
            " - 0s - loss: 3.9512 - acc: 0.2695 - val_loss: 1.4894 - val_acc: 0.2778\n",
            "Epoch 91/100\n",
            " - 0s - loss: 3.9224 - acc: 0.2535 - val_loss: 1.5163 - val_acc: 0.3651\n",
            "Epoch 92/100\n",
            " - 0s - loss: 3.9528 - acc: 0.3014 - val_loss: 1.5103 - val_acc: 0.1825\n",
            "Epoch 93/100\n",
            " - 0s - loss: 4.0478 - acc: 0.1597 - val_loss: 1.4559 - val_acc: 0.4683\n",
            "Epoch 94/100\n",
            " - 0s - loss: 3.9939 - acc: 0.2475 - val_loss: 1.6906 - val_acc: 0.1429\n",
            "Epoch 95/100\n",
            " - 0s - loss: 3.9559 - acc: 0.2595 - val_loss: 1.5321 - val_acc: 0.1905\n",
            "Epoch 96/100\n",
            " - 0s - loss: 4.0164 - acc: 0.2475 - val_loss: 1.5499 - val_acc: 0.3175\n",
            "Epoch 97/100\n",
            " - 0s - loss: 3.9523 - acc: 0.1916 - val_loss: 1.5820 - val_acc: 0.3095\n",
            "Epoch 98/100\n",
            " - 0s - loss: 3.8779 - acc: 0.3194 - val_loss: 1.5345 - val_acc: 0.3810\n",
            "Epoch 99/100\n",
            " - 0s - loss: 3.8870 - acc: 0.3034 - val_loss: 1.5115 - val_acc: 0.2698\n",
            "Epoch 100/100\n",
            " - 0s - loss: 3.8726 - acc: 0.3074 - val_loss: 1.5093 - val_acc: 0.4127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPmwP_8lVOyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTIT9IwlQg9B",
        "colab_type": "code",
        "outputId": "bac21f3c-1c08-46c0-d770-dcd5655062cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "np.argmax(model.predict_proba(df_test),axis = 1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 4, 1, 4, 4, 4, 1, 0, 0, 0, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4,\n",
              "       1, 4, 4, 0, 0, 4, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 1, 4, 4, 0, 4, 1,\n",
              "       4, 1, 0, 4, 4, 4, 1, 4, 4, 4, 0, 4, 0, 4, 0, 4, 4, 0, 1, 1, 4, 1,\n",
              "       4, 4, 4, 0, 4, 4, 4, 0, 4, 1, 4, 0, 4, 4, 1, 4, 4, 4, 1, 4, 4, 4,\n",
              "       3, 4, 4, 4, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4,\n",
              "       0, 4, 4, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 0, 0, 0, 4, 4, 4, 4, 1, 4,\n",
              "       4, 0, 4, 4, 4, 0, 0, 1, 4, 4, 0, 4, 4, 4, 1, 1, 4, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30YQyamOVN8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SQLF2RpTXYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}